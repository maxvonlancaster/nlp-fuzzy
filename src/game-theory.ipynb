{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7b6e05",
   "metadata": {},
   "source": [
    "# Some general ideas related to game theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515f5c6",
   "metadata": {},
   "source": [
    "## Poker Problem \n",
    "\n",
    "Kuhn Poker: 1,2,3 -> \n",
    "\n",
    "Two pleyer\n",
    "$$a_{}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab420b6c",
   "metadata": {},
   "source": [
    "## Adversarial Generation of Short Prompts for Improving Feedback Quality\n",
    "\n",
    "**Motivation**\n",
    "\n",
    "User feedback (reviews, evaluations, surveys) is often affected by cognitive biases, emotional tone, and low informational density. Respondents tend to provide vague, emotionally charged, or socially biased answers, which reduces the usefulness of feedback for decision-making and analysis. This problem is especially pronounced in educational evaluations, product reviews, and employee assessments.\n",
    "\n",
    "\n",
    "How can short textual prompts be adaptively generated to maximize the information content and reduce bias in customer feedback, under adversarial evaluation?\n",
    "\n",
    "feedback quality metrics\n",
    "- Information content I(r) (number of distinct product aspects mentioned, or entropy of aspect distribution, or coverage of predefined aspect set)\n",
    "- Bias metric B(r) (sentiment extremeness (absolute sentiment score), demographic skew (if groups exist), lexical subjectivity score.)\n",
    "- Utility U(r) (Human usefulness. Collect later via human ratings 1‚Äì5. At the beginning, can be ignored)\n",
    "\n",
    "GAME:\n",
    "Generator (G) produces a short prompt p, Evaluator (E) evaluates the resulting feedback r.\n",
    "G: finite set of prompt types (templates); E: fixed scoring function (at first)\n",
    "\n",
    "Payoff: $u_{G}‚Äã(p)=\\alpha I(r)‚àí\\beta B(r)$\n",
    "Evaluator payoff: $uE‚Äã(p)=‚àíuG‚Äã(p)$ -- this is for now a zero-sum game\n",
    "\n",
    "The game is between a Prompt Generator and an Evaluator of feedback quality, where the generator tries to elicit informative, low-bias feedback, and the evaluator penalizes bias and low information.\n",
    "\n",
    "BASELINE PIPELINE:\n",
    "- Create a small prompt set - pure strategies\n",
    "- Collect responses (may simulate using LLM)\n",
    "- NLP analysis: extract aspects (rule-based or simple classifier), compute sentiment score.\n",
    "\n",
    "payoff matrix\n",
    "\n",
    "Now: eliminate dominated prompts, compute mixed strategies, identify equilibrium distributions.\n",
    "\n",
    "FURTHER:\n",
    "adversarial learning\n",
    "- Parameterize the prompt - Instead of fixed templates, represent prompt as (length,specificity,number of constraints,presence of examples) -> vector $\\theta$\n",
    "- Train generator, using RL (action = generate prompt parameters, reward = $u_{G}$, environment = evaluator + NLP pipeline.)\n",
    "- \n",
    "\n",
    "comparison of prompts before and after optimization, statistical improvement in I and reduction in B, robustness analysis across datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c31f1",
   "metadata": {},
   "source": [
    "## Adversarial Generation of Short Prompts for Improving Feedback Quality\n",
    "\n",
    "customer feedback in textual form\n",
    "\n",
    "$$R=\\{all-possible-feedback-texts\\}$$\n",
    "\n",
    "$$P=\\{all possible short prompts\\}$$\n",
    "\n",
    "Given a prompt $p\\in P$, the user (environment) generates a feedback text:\n",
    "\n",
    "$$r‚àºP(‚ãÖ‚à£p),r\\in R$$\n",
    "\n",
    "The distribution is unknown and stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffb4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "SECRET_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "PROMPTS = [\n",
    "    \"What did you like about the product?\",\n",
    "    \"What problems did you face while using the product?\",\n",
    "    \"Please describe your experience with the product.\",\n",
    "    \"What should we improve in the product?\",\n",
    "    \"How satisfied are you with the product and why?\"\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=SECRET_KEY)\n",
    "\n",
    "def generate_feedback(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a customer giving honest feedback.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.9, # may be try variate temperature\n",
    "        max_tokens=120\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a5779",
   "metadata": {},
   "source": [
    "Let $A=\\{ a_{1}, ...,a_{k} \\}$ be a predefined set of product aspects.\n",
    "\n",
    "Define an aspect extraction function: $\\phi :R\\rightarrow 2^{A}$\n",
    "\n",
    "Information content: $I(r)=‚à£\\phi (r)‚à£$\n",
    "\n",
    "Lexical divercity:\n",
    "\n",
    "$$I(r) = \\frac{unique tokens}{total tokens}$$\n",
    "\n",
    "DEFINE BETTER FUNCTION LATER!\n",
    "\n",
    "Bias metric:\n",
    "\n",
    "$$B(r)=|s(r)|$$\n",
    "\n",
    "Where \n",
    "$s(r)\\in [‚àí1,1] $ - sentiment polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7d863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def information_metric(text):\n",
    "    tokens = re.findall(r\"\\w+\", text.lower())\n",
    "    if len(tokens) == 0:\n",
    "        return 0.0\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "def bias_metric(text):\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    return abs(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50573e7b",
   "metadata": {},
   "source": [
    "Empirical expectation (Monte Carlo)\n",
    "\n",
    "Since feedback is stochastic, we work with expectations.\n",
    "\n",
    "$$E[B‚à£p]=E_{r‚àºP(‚ãÖ‚à£p)}‚Äã[B(r)]$$\n",
    "$$E[I‚à£p]=E_{r‚àºP(‚ãÖ‚à£p)}‚Äã[I(r)]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4e1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def estimate_expectations(prompt, n_samples=10):\n",
    "    infos, biases = [], []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        r = generate_feedback(prompt)\n",
    "        infos.append(information_metric(r))\n",
    "        biases.append(bias_metric(r))\n",
    "\n",
    "    return np.mean(infos), np.mean(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713d8ba",
   "metadata": {},
   "source": [
    "**Payoff function (parametrized)**\n",
    "\n",
    "Player G (Generator) chooses prompt p\n",
    "\n",
    "Player E (Evaluator) enforces quality constraints\n",
    "\n",
    "Strategy spaces\n",
    "\n",
    "Generator strategies:\n",
    "\n",
    "$p\\in P$\n",
    "\n",
    "Evaluator strategies:\n",
    "\n",
    "$$\\lambda = (\\alpha, \\beta)\\in \\mathbb{R}_{+}^{2}$$\n",
    "\t‚Äã\n",
    "Evaluator controls the penalty weights.\n",
    "\n",
    "Generator payoff:\n",
    "\n",
    "$$u_G‚Äã(p,Œª)=Œ±E[I‚à£p]‚àíŒ≤E[B‚à£p]$$\n",
    "\n",
    "Evaluator payoff:\n",
    "\n",
    "$$u_E‚Äã(p,Œª)=‚àíu_G‚Äã(p,Œª)$$\n",
    "\n",
    "**Static game with finite strategies:**\n",
    "\n",
    "Finite prompts: $P={p_1‚Äã,‚Ä¶,p_n‚Äã}$\n",
    "\n",
    "Define payoff: $U_i‚Äã=Œ±E[I‚à£p_i‚Äã]‚àíŒ≤E[B‚à£p_i‚Äã]$\n",
    "\n",
    "$p_{i}$ is dominated by $p_{j}$ if $U_j‚Äã‚â•U_i‚Äã$. Dominated prompts can be eliminated.\n",
    "\n",
    "We seek a minimax equillibrium $\\max_{\\pi} \\min_{\\alpha, \\beta} U_{G}(\\pi, \\lambda)$\n",
    "\n",
    "\n",
    "THINK ABOUT LATER: Dynamic learning formulation, \n",
    "Let prompts be generated by parameters: $p=g(\\theta),\\theta \\in \\mathbb{R}^{d}$\n",
    "\n",
    "Constraints on parameters: $\\alpha+\\beta=1$, $u_{E}‚Äã=‚àíu_{G}‚Äã‚àíc(\\beta)$ ($c(\\beta)=\\gamma \\beta^{2}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a3b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff(prompt, alpha=1.0, beta=1.0, n_samples=10):\n",
    "    I_hat, B_hat = estimate_expectations(prompt, n_samples)\n",
    "    return alpha * I_hat - beta * B_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0f934",
   "metadata": {},
   "source": [
    "Playing the game (best response)\n",
    "\n",
    "The generator chooses the best prompt given evaluator parameters.\n",
    "\n",
    "THINK ABOUT LATER: Transformer as Prompt Generator\n",
    "\n",
    "Prompt as a function of parameters, instead of choosing a prompt directly, define: $p_{\\theta} =G_{\\theta}‚Äã(z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b3303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best prompt: What problems did you face while using the product?\n",
      "What did you like about the product?... -> 0.5290\n",
      "What problems did you face while using t... -> 0.7067\n",
      "Please describe your experience with the... -> 0.6287\n",
      "What should we improve in the product?... -> 0.6033\n",
      "How satisfied are you with the product a... -> 0.5855\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def best_prompt(prompts, alpha, beta):\n",
    "    scores = {}\n",
    "    for p in prompts:\n",
    "        scores[p] = payoff(p, alpha, beta)\n",
    "    return max(scores, key=scores.get), scores\n",
    "\n",
    "best, all_scores = best_prompt(PROMPTS, alpha=1.0, beta=0.7)\n",
    "\n",
    "print(\"Best prompt:\", best)\n",
    "for p, s in all_scores.items():\n",
    "    print(f\"{p[:40]}... -> {s:.4f}\")\n",
    "\n",
    "# BETAS = [0.2, 0.5, 1.0, 2.0]\n",
    "\n",
    "# for beta in BETAS:\n",
    "#     best, _ = best_prompt(PROMPTS, alpha=1.0, beta=beta)\n",
    "#     print(f\"beta={beta:.1f} -> best prompt: {best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052b4ae",
   "metadata": {},
   "source": [
    "TODO\n",
    "- may be real scenario of application (online shop)\n",
    "- Named entity recognition (nlp topic) for I(r), think B(r) (fuzzy logic)\n",
    "- Reinforcement learning (contextual bandit) for players to choose parameters \n",
    "- Dynamic learning formulation, Let prompts be generated by parameters: $p=g(\\theta),\\theta \\in \\mathbb{R}^{d}$ (transformers)\n",
    "- qualatative metrics of approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6e0f9",
   "metadata": {},
   "source": [
    "## Improved Game\n",
    "\n",
    "- improve calculation of functions I(r) and B(r)\n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "I(r) calculation: $A$ - set of aspects, $R$ - response space\n",
    "\n",
    "$$aspects: R -> 2^{A}$$\n",
    "\n",
    "$I_{a}(r) = \\frac{|aspects(r)|}{|A|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b34ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\vmelnyk2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import spacy \n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "load_dotenv()\n",
    "SECRET_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "PROMPTS = [\n",
    "    \"What did you like about the product?\",\n",
    "    \"What problems did you face while using the product?\",\n",
    "    \"Please describe your experience with the product.\",\n",
    "    \"What should we improve in the product?\",\n",
    "    \"How satisfied are you with the product and why?\"\n",
    "]\n",
    "\n",
    "client = OpenAI(api_key=SECRET_KEY)\n",
    "\n",
    "def generate_feedback(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a customer giving honest feedback.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.9, # may be try variate temperature\n",
    "        max_tokens=120\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# utility functions definition\n",
    "ASPECTS = {\n",
    "    \"price\": [\"price\", \"cost\", \"expensive\", \"cheap\"],\n",
    "    \"delivery\": [\"delivery\", \"shipping\", \"arrived\"],\n",
    "    \"quality\": [\"quality\", \"broken\", \"durable\"],\n",
    "    \"support\": [\"support\", \"service\", \"help\"],\n",
    "    \"usability\": [\"easy\", \"difficult\", \"interface\", \"ui\"],\n",
    "    \"performance\": [\"fast\", \"slow\", \"lag\"]\n",
    "}\n",
    "SUGGESTION_PATTERNS = [\n",
    "    \"should\", \"could\", \"recommend\", \"improve\", \"add\", \"fix\" # \"it would be better\"\n",
    "]\n",
    "EMOTION_WORDS = {\"amazing\", \"terrible\", \"horrible\", \"fantastic\", \"worst\"}\n",
    "\n",
    "def information_metric_aspect(text):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    lemmas = {token.lemma_ for token in doc if token.is_alpha} # lemmatization\n",
    "\n",
    "    found = set()\n",
    "    \n",
    "    for aspect, keywords in ASPECTS.items():\n",
    "        keyword_lemmas = {nlp(k)[0].lemma_ for k in keywords}\n",
    "        if lemmas.intersection(keyword_lemmas):\n",
    "            found.add(aspect)\n",
    "    \n",
    "    return len(found), found\n",
    "\n",
    "\n",
    "def information_metric_actionability(text):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    lemmas = {t.lemma_ for t in doc if t.is_alpha}\n",
    "\n",
    "    found = []\n",
    "    suggestion_lemmas = {nlp(s)[0].lemma_ for s in SUGGESTION_PATTERNS}\n",
    "    for l in suggestion_lemmas:\n",
    "        if l in lemmas:\n",
    "            found.append(l)\n",
    "    \n",
    "    return len(found)/len(suggestion_lemmas), found\n",
    "\n",
    "# number of distinct entities mentioned\n",
    "def information_metric_ner(text):\n",
    "    doc = nlp(text)\n",
    "    return len(doc.ents) / len(doc), [e.text for e in doc.ents]\n",
    "\n",
    "def information_metric_combined(text):\n",
    "    n = 2\n",
    "    w = [0.4, 0.3, 0.3]\n",
    "    aspect_metric, _ = information_metric_aspect(text)\n",
    "    actionability_metric, _ = information_metric_actionability(text)\n",
    "    ner_metric, _ = information_metric_ner(text)\n",
    "\n",
    "    return ((aspect_metric**n)*w[0] + (actionability_metric**n)*w[1] + (ner_metric**n)*w[2])**(1/n)\n",
    "\n",
    "\n",
    "def bias_metric_ner(text):\n",
    "    doc = nlp(text.lower())\n",
    "    lemmas = {t.lemma_ for t in doc if t.is_alpha}\n",
    "\n",
    "    found = []\n",
    "    emotion_lemmas = {nlp(s)[0].lemma_ for s in EMOTION_WORDS}\n",
    "    for l in emotion_lemmas:\n",
    "        if l in lemmas:\n",
    "            found.append(l)\n",
    "    \n",
    "    return len(found) / len(emotion_lemmas), found\n",
    "\n",
    "nltk.download(\"vader_lexicon\")\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def bias_sentiment_intencity(text):\n",
    "    score = sia.polarity_scores(text)[\"compound\"]\n",
    "    return abs(score)\n",
    "\n",
    "\n",
    "def bias_metric_combined(text):\n",
    "    n = 2\n",
    "    w = [0.5, 0.5]\n",
    "    ner, _ = bias_metric_ner(text)\n",
    "    polarity = bias_sentiment_intencity(text)\n",
    "\n",
    "    return ((ner**n)*w[0] + (polarity**n)*w[1])**(1/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f3b4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, {'support'})\n",
      "(0.0, [])\n",
      "(0.022222222222222223, ['about three weeks ago', 'night', 'five minutes', 'evening', 'one'])\n",
      "0.6325726425859312\n",
      "(0.0, [])\n",
      "0.9958\n",
      "0.7041369327055641\n"
     ]
    }
   ],
   "source": [
    "test_response = \"\"\"\"Hey there!\n",
    "I bought the EchoHome Smart Lamp about three weeks ago, mostly because I was tired of harsh overhead lighting while reading at night. I wasn‚Äôt sure what to expect ‚Äî sometimes ‚Äúsmart‚Äù gadgets feel more complicated than they‚Äôre worth ‚Äî but this one? Totally different story.\n",
    "Setting it up took maybe five minutes with the app, and since then it‚Äôs become my favorite part of my evening routine. I love that I can adjust the color temperature from bright white for work to a soft amber for winding down. The sunset fade-out feature actually helps me fall asleep ‚Äî no joke!\n",
    "My cat is also weirdly obsessed with it (she sits under it like it‚Äôs her personal sun), so that‚Äôs an unexpected bonus. üò∏\n",
    "If I had one tiny wish: I‚Äôd love a physical remote control option for when my phone isn‚Äôt nearby. But honestly, it‚Äôs such a small thing compared to how much I enjoy using it.\n",
    "Thanks for making a product that feels both thoughtful and genuinely useful. It‚Äôs the little things that make a home cozy, right?\n",
    "Cheers, Alex\"\"\"\n",
    "\n",
    "print(information_metric_aspect(test_response))\n",
    "print(information_metric_actionability(test_response))\n",
    "print(information_metric_ner(test_response))\n",
    "print(information_metric_combined(test_response))\n",
    "\n",
    "print(bias_metric_ner(test_response))\n",
    "print(bias_sentiment_intencity(test_response))\n",
    "print(bias_metric_combined(test_response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38736072",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
