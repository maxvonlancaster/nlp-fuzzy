{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce49dca",
   "metadata": {},
   "source": [
    "# Game-Theoretic Approach to NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e1154",
   "metadata": {},
   "source": [
    "TBD: describe\n",
    "\n",
    "Reinforcement Learning with Human-in-the-Loop (RLHF) setup, with two agents:\n",
    "\n",
    "- Agent A: Text generator (e.g., a simple model or GPT-based).\n",
    "- Agent B: Evaluator that scores Agent Aâ€™s output based on a modifiable matrix.\n",
    "- Human: Oversees the process and can manually adjust the evaluation matrix used by B.\n",
    "\n",
    "This kind of framework could be used for dialogue training, text summarization, creative writing, or even value alignment experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4828ba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 0 ---\n",
      "Generated: Tell me a story with extra words 2\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 1 ---\n",
      "Generated: Tell me a story with extra words 9\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 2 ---\n",
      "Generated: Tell me a story with extra words 1\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 3 ---\n",
      "Generated: Tell me a story with extra words 5\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 4 ---\n",
      "Generated: Tell me a story with extra words 6\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 5 ---\n",
      "Generated: Tell me a story with extra words 1\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 6 ---\n",
      "Generated: Tell me a story with extra words 7\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 7 ---\n",
      "Generated: Tell me a story with extra words 8\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 8 ---\n",
      "Generated: Tell me a story with extra words 2\n",
      "Reward: 0.45\n",
      "\n",
      "--- Step 9 ---\n",
      "Generated: Tell me a story with extra words 5\n",
      "Reward: 0.45\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# === Agent A: text generator (naive implementation) ===\n",
    "class AgentA:\n",
    "    def __init__(self):\n",
    "        self.temperature = 1.0  # will be tuned based on feedback\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        # In a real case, this could be a language model\n",
    "        return f\"{prompt} with extra words {random.randint(0, int(10 * self.temperature))}\"\n",
    "\n",
    "    def update(self, reward):\n",
    "        # Simple feedback: increase \"risk\" (temperature) if rewarded\n",
    "        self.temperature += 0.1 * (reward - 0.5)  # normalize around 0.5\n",
    "        self.temperature = max(0.1, min(self.temperature, 2.0))\n",
    "\n",
    "\n",
    "# === Agent B: evaluator using a matrix ===\n",
    "class AgentB:\n",
    "    def __init__(self, matrix=None):\n",
    "        self.matrix = matrix or {\n",
    "            \"length_weight\": 1.0,\n",
    "            \"keyword_weight\": 1.0,\n",
    "            \"positivity_weight\": 1.0,\n",
    "        }\n",
    "\n",
    "    def evaluate(self, text):\n",
    "        score = 0\n",
    "        score += self.matrix[\"length_weight\"] * len(text.split())\n",
    "        score += self.matrix[\"keyword_weight\"] * (\"extra\" in text)\n",
    "        score += self.matrix[\"positivity_weight\"] * (\"good\" in text)\n",
    "        return min(score / 20.0, 1.0)  # normalize to [0,1]\n",
    "\n",
    "    def update_matrix(self, new_matrix):\n",
    "        self.matrix = new_matrix\n",
    "\n",
    "\n",
    "# === Human interface ===\n",
    "def human_adjust_matrix(matrix):\n",
    "    print(\"\\nCurrent matrix:\", matrix)\n",
    "    key = input(\"Change which weight (length/keyword/positivity)? Leave empty to skip: \").strip()\n",
    "    if key in matrix:\n",
    "        new_val = float(input(f\"New value for {key}: \"))\n",
    "        matrix[key] = new_val\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# === Training loop ===\n",
    "def training_loop():\n",
    "    agent_a = AgentA()\n",
    "    agent_b = AgentB()\n",
    "    \n",
    "    for step in range(10):\n",
    "        print(f\"\\n--- Step {step} ---\")\n",
    "        prompt = \"Tell me a story\"\n",
    "        text = agent_a.generate(prompt)\n",
    "        reward = agent_b.evaluate(text)\n",
    "\n",
    "        print(f\"Generated: {text}\")\n",
    "        print(f\"Reward: {reward:.2f}\")\n",
    "\n",
    "        agent_a.update(reward)\n",
    "\n",
    "        user_input = input(\"Do you want to adjust evaluator? (y/n): \")\n",
    "        if user_input.lower().startswith('y'):\n",
    "            new_matrix = human_adjust_matrix(agent_b.matrix)\n",
    "            agent_b.update_matrix(new_matrix)\n",
    "\n",
    "training_loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08453d",
   "metadata": {},
   "source": [
    "## Where to start:\n",
    "- How to code an agent?\n",
    "- Vecotrization: 1,2 test data\n",
    "- Evaluation: binary cross-entropy \n",
    "- \n",
    "\n",
    "- Be more concentrated on context in dialogue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781fa4f",
   "metadata": {},
   "source": [
    "## General Idea:\n",
    "A, B \n",
    "\n",
    "B prompts A\n",
    "A answers B\n",
    "B evaluates A\n",
    "B prompts A (2)\n",
    "A ansers\n",
    "B evaluates prompt (1) and prompt (2)\n",
    "\n",
    "We have to have a matrix of context on the side of A\n",
    "\n",
    "Where game theory is?\n",
    "\n",
    "Human in the loop (H), H tracks interaction between A and B, and adjustes the matrix that B has;\n",
    "\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- Trajection analysis (trajection: sequence of prompts and evaluations)\n",
    "- Direction alignment \n",
    "- Policy gradient algorithm\n",
    "- Rejection sampling\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca0e43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218be4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
